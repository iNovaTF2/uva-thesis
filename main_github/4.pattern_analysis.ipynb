{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoolQ - BERT - Main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import io\n",
    "import PIL\n",
    "from PIL import Image, ImageEnhance\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform for CNN\n",
    "from torchvision import transforms\n",
    "input_size = 224\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),  # Resize all images to the same size\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes, input_size=input_size):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolutional Layer 3\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Convolutional Layer 4\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolutional Layer 5\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Adjusted size calculation after 5 pooling layers\n",
    "        size_after_conv = input_size // 32  # Each pooling layer halves the dimension\n",
    "        self.fc1 = nn.Linear(256 * size_after_conv * size_after_conv, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.act1(self.conv1(x)))\n",
    "        x = self.pool2(self.act2(self.conv2(x)))\n",
    "        x = self.pool3(self.act3(self.conv3(x)))\n",
    "        x = self.pool4(self.act4(self.conv4(x)))\n",
    "        x = self.pool5(self.act5(self.conv5(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"boolq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pairs = [[row['question'], row['passage']] for row in dataset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model link and tokenizer\n",
    "model_link = \"rycecorn/bert-fine-tuned-boolq\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_link)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_link, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_self_attention_matrix(input_sentence, attention_head):\n",
    "    test = input_pairs[input_sentence]\n",
    "    tokenized_input = tokenizer(test[0], test[1], truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "      outputs = model(**tokenized_input)\n",
    "    attention_outputs = torch.stack(outputs.attentions)\n",
    "    flattened_attention_matrices = attention_outputs.view(-1, attention_outputs.size(3), attention_outputs.size(4))\n",
    "    flattened_attention_matrices = flattened_attention_matrices\n",
    "    \n",
    "    selected_attention_head = flattened_attention_matrices[attention_head].cpu().numpy()\n",
    "    \n",
    "      # Clear intermediate variables\n",
    "    del test, tokenized_input, outputs, attention_outputs, flattened_attention_matrices\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return selected_attention_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_head_pattern(attention_pattern):\n",
    "    # plot attention pattern\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(attention_pattern, cmap='magma', interpolation='nearest')\n",
    "    \n",
    "    #Convert to bytes and to image file\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    png_variable = buf.getvalue()\n",
    "    image_buffer = io.BytesIO(png_variable)\n",
    "    \n",
    "    # Close buffer - delete from memory\n",
    "    buf.close()\n",
    "    \n",
    "    # Prep image for CNN\n",
    "    img = PIL.Image.open(image_buffer)\n",
    "    imgCropped = img.crop(box= (205, 96, 820, 713))\n",
    "    enhancer = PIL.ImageEnhance.Contrast(imgCropped)\n",
    "    enhanced_image = enhancer.enhance(4.0)\n",
    "    gray_image = enhanced_image.convert(\"L\")\n",
    "    img = transform(gray_image.convert('RGB'))\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    # Clear intermediate variables and collect garbage\n",
    "    del attention_pattern, png_variable, imgCropped, enhancer, enhanced_image, gray_image\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = torch.load('ahr_cnn_75_acc.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_number = random.randint(0, 999)\n",
    "head_number = random.randint(0, 73)\n",
    "print(f'Input num: {sentence_number}')\n",
    "print(f'Head num: {head_number}')\n",
    "\n",
    "head_check = get_self_attention_matrix(sentence_number, head_number)\n",
    "test_img = classify_head_pattern(head_check)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model_cnn(test_img)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    print(f'Predicted class: {predicted.item()}') # Labels for classifier are range 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads_to_prune = [34, 42, 29, 60, 59, 58, 43, 40, 44, 55, 53, 27, 51, 48, 50, 25, 45, 33, 49, 38, 52, 54, 31, 56, 39, 32, 36, 35, 37, 57, 28, 47, 63, 46, 70, 30, 16, 26, 15, 18, 64, 7, 68, 8, 71, 20, 62, 5, 24, 72, 66, 61, 12, 14, 6, 65, 67, 17, 1, 69, 23, 41, 10, 21, 9, 2, 19, 4]\n",
    "attention_pattern_dict = {i: [0, 0, 0, 0, 0] for i in range(1, 145)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for head in tqdm(heads_to_prune, desc='head_count'):\n",
    "    head_num_in_model = head - 1 # For index purpose\n",
    "    i = 0\n",
    "    while i != 80:\n",
    "        sentence_number = random.randint(0, len(input_pairs) - 1)\n",
    "        head_attention_matrix = get_self_attention_matrix(sentence_number, head_num_in_model)\n",
    "        matrix_to_img = classify_head_pattern(head_attention_matrix)\n",
    "        with torch.no_grad():\n",
    "            output = model_cnn(matrix_to_img)\n",
    "            _, predicted = torch.max(output, 1) # predicted.item() to get class\n",
    "\n",
    "        # Update attention_pattern_dict\n",
    "        attention_pattern_dict[head][predicted.item()] += 1\n",
    "        i += 1\n",
    "        # Clear variables and collect garbage\n",
    "        del head_attention_matrix, matrix_to_img, output\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "with open('analysis_BERT_boolq_attention_prune_count.pickle', 'wb') as f:\n",
    "    pickle.dump(attention_pattern_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot patterns for each head pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pattern count for each head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'analysis_BERT_boolq_attention_prune_count.pickle'\n",
    "\n",
    "# Open the pickle file and load the data\n",
    "with open(file_path, 'rb') as file:\n",
    "    head_attention_count = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get heads pruned at each interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: [44, 43, 38, 41, 58, 65, 80],\n",
       " 0.1: [45, 63, 51, 81, 39, 91, 96],\n",
       " 0.15: [92, 49, 53, 103, 100, 88, 52, 50],\n",
       " 0.2: [66, 75, 55, 74, 76, 57, 97],\n",
       " 0.25: [72, 87, 73, 69, 62, 99, 56],\n",
       " 0.3: [101, 37, 83, 118, 47, 67, 98],\n",
       " 0.35: [61, 102, 59, 68, 86, 64, 90],\n",
       " 0.4: [77, 60, 138, 144, 136, 84, 120, 133],\n",
       " 0.45: [131, 122, 115, 139, 104, 40, 124],\n",
       " 0.5: [126, 125, 132, 78, 143, 93, 105],\n",
       " 0.55: [135, 128, 31, 79, 127, 82, 129],\n",
       " 0.6: [141, 130, 106, 123, 108, 22, 121],\n",
       " 0.65: [13, 95, 94, 54, 137, 109, 28, 70],\n",
       " 0.7: [107, 21, 85, 134, 32, 18, 119],\n",
       " 0.75: [112, 71, 27, 48, 116, 89, 114],\n",
       " 0.8: [140, 113, 111, 16, 142, 8, 35],\n",
       " 0.85: [33, 6, 5, 36, 10, 29, 7],\n",
       " 0.9: [117, 1, 20, 24, 30, 15, 2, 26],\n",
       " 0.95: [110, 12, 9, 46, 23, 3, 14]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('BERT_BoolQ_heads_pruned.pkl', 'rb') as f:\n",
    "    head_prune_intervals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary with attention head and number of patterns pruned from each head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_heads_attention_pattern_count = {i: [0, 0, 0, 0, 0] for i in np.around(np.arange(0, 0.96, 0.05), 2)}\n",
    "for i in head_prune_intervals:\n",
    "    for head in head_prune_intervals[i]:\n",
    "        pruned_heads_attention_pattern_count[i] = [a + b for a, b in zip(head_attention_count[head], pruned_heads_attention_pattern_count[i])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get cumulative pattern at each interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cumulative dictionary\n",
    "def calculate_cumulative(attention_patterns):\n",
    "    cumulative_patterns = {}\n",
    "    cumulative_sum = [0, 0, 0, 0, 0]\n",
    "\n",
    "    for key in sorted(attention_patterns.keys()):\n",
    "        cumulative_sum = [a + b for a, b in zip(cumulative_sum, attention_patterns[key])]\n",
    "        cumulative_patterns[key] = cumulative_sum.copy()\n",
    "    \n",
    "    return cumulative_patterns\n",
    "\n",
    "cumulative_patterns = calculate_cumulative(pruned_heads_attention_pattern_count)\n",
    "cumulative_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for proportion of patterns at each pruning interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pruned_heads_attention_pattern_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated code to plot with specified modifications\n",
    "\n",
    "# Convert dictionary to list for plotting\n",
    "labels = list(data.keys())\n",
    "values = np.array(list(data.values()))\n",
    "\n",
    "# Calculate proportions\n",
    "proportions = values / values.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Define new category labels\n",
    "category_labels = ['Vertical', 'Diagonal', 'Vert + Diag', 'Block', 'Homogenous']\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # Increased the height of the figure to 12\n",
    "\n",
    "# Define bar width and positions\n",
    "bar_width = 0.8  # Increased the bar width\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# Plot stacked bar chart with proportions\n",
    "bottom = np.zeros(len(labels))\n",
    "for i in range(proportions.shape[1]):\n",
    "    ax.bar(x, proportions[:, i], bar_width, bottom=bottom, label=category_labels[i])\n",
    "    bottom += proportions[:, i]\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Key')\n",
    "ax.set_ylabel('Proportion')\n",
    "ax.set_title('Prune proportions - BERT - BoolQ')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Add space between bars\n",
    "for bar in ax.patches:\n",
    "    bar.set_x(bar.get_x() + 0.05)\n",
    "    bar.set_width(bar.get_width() - 0.1)\n",
    "\n",
    "plt.savefig('./outputs/pruned_props_BERT_BoolQ.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for cumulative proportion of patterns at each pruning interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to list for plotting\n",
    "labels = list(cumulative_patterns.keys())\n",
    "values = np.array(list(cumulative_patterns.values()))\n",
    "\n",
    "# Calculate proportions\n",
    "proportions = values / values.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Define new category labels\n",
    "category_labels = ['Vertical', 'Diagonal', 'Vert + Diag', 'Block', 'Homogenous']\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # Increased the height of the figure to 12\n",
    "\n",
    "# Define bar width and positions\n",
    "bar_width = 0.8  # Increased the bar width\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# Plot stacked bar chart with proportions\n",
    "bottom = np.zeros(len(labels))\n",
    "for i in range(proportions.shape[1]):\n",
    "    ax.bar(x, proportions[:, i], bar_width, bottom=bottom, label=category_labels[i])\n",
    "    bottom += proportions[:, i]\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Key')\n",
    "ax.set_ylabel('Proportion')\n",
    "ax.set_title('Prune cumulative proportions - BERT - BoolQ')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Add space between bars\n",
    "for bar in ax.patches:\n",
    "    bar.set_x(bar.get_x() + 0.05)\n",
    "    bar.set_width(bar.get_width() - 0.1)\n",
    "\n",
    "plt.savefig('./outputs/cumu_props_BERT_BoolQ.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for pruned patterns trend over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting keys and values\n",
    "x = list(data.keys())\n",
    "y_values = list(zip(*data.values()))\n",
    "\n",
    "# Plotting the data with the new labels and all ticks on the x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for y in y_values:\n",
    "    plt.plot(x, y)\n",
    "\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Pruned Patterns - BERT - BoolQ')\n",
    "plt.xticks(x)  # Show all ticks on the x-axis\n",
    "plt.legend(['Vertical', 'Diagonal', 'Vert + Diag', 'Block', 'Homogenous'], loc='lower left', fontsize='small')\n",
    "plt.grid(True)\n",
    "plt.savefig('/home/jovyan/Thesis/ahr_pattern_prune_analysis/outputs/pruned_patterns_BERT_BoolQ.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
